ğŸ“˜ README COMPLETO â€“ News Aggregator
ğŸ“° News Aggregator â€“ Sistema de Scraping y GestiÃ³n de Noticias

Sistema completo para scraping, gestiÃ³n y anÃ¡lisis de noticias peruanas, con autenticaciÃ³n de usuarios, planes de servicio, anÃ¡lisis con IA y un panel administrativo moderno.

ğŸ“‹ 1. DescripciÃ³n General

Este proyecto integra:

ğŸ” Scraping automatizado y manual de mÃºltiples portales de noticias peruanas

ğŸ§  AnÃ¡lisis de noticias con Inteligencia Artificial (Google Gemini AI)

ğŸ‘¤ AutenticaciÃ³n con roles (Usuario / Admin)

ğŸ“Š Panel administrativo completo

ğŸ” Sistema de planes Free y Plus

ğŸ§¾ ExportaciÃ³n de datos a Excel

ğŸŒ API RESTful documentada con Swagger

ğŸ¨ Frontend moderno en React + TypeScript

Ideal para:

Monitoreo de noticias

Empresas de marketing digital

Prensa

InvestigaciÃ³n acadÃ©mica

AutomatizaciÃ³n informativa

âš™ï¸ 2. TecnologÃ­as Usadas
Backend

FastAPI

Python 3.10+

MySQL 8.0

SQLAlchemy ORM

JWT (AutenticaciÃ³n)

BeautifulSoup + Requests (Scraping)

Google Gemini AI

Frontend

React + TypeScript

Vite

Axios

TailwindCSS

Zustand (estado global)

ğŸ› ï¸ 3. InstalaciÃ³n y ConfiguraciÃ³n
ğŸ“¥ 3.1 Clonar el Repositorio
git clone https://github.com/maykolaracayo22/scraping_noticias.git
cd scraping_noticias

ğŸ”§ 3.2 Backend â€“ InstalaciÃ³n
ğŸ“Œ Entrar a la carpeta backend
cd backend

ğŸ“Œ Crear entorno virtual
python -m venv venv
source venv/bin/activate   # Linux
venv\Scripts\activate      # Windows

ğŸ“Œ Instalar dependencias
pip install -r requirements.txt

ğŸ”‘ 3.3 Configurar Variables de Entorno

Crea un archivo .env dentro de /backend:

DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=tu_password
DB_NAME=scrapingdb

SECRET_KEY=tu_clave_secreta
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

GEMINI_API_KEY=TU_API_KEY

ğŸ—„ï¸ 3.4 Configurar Base de Datos MySQL
CREATE DATABASE scrapingdb;

CREATE USER 'scraping_user'@'%' IDENTIFIED BY 'password123';
GRANT ALL PRIVILEGES ON scrapingdb.* TO 'scraping_user';
FLUSH PRIVILEGES;

â–¶ï¸ 3.5 Ejecutar Backend
uvicorn main:app --reload


La API estarÃ¡ en:

ğŸ‘‰ http://localhost:8000

ğŸ‘‰ DocumentaciÃ³n Swagger: http://localhost:8000/docs

ğŸ¨ 3.6 Frontend â€“ InstalaciÃ³n
ğŸ“Œ Entrar a la carpeta
cd frontend

ğŸ“Œ Instalar dependencias
npm install

ğŸ“Œ Ejecutar en modo desarrollo
npm run dev


Frontend en:
ğŸ‘‰ http://localhost:5173

ğŸ“ 4. Estructura del Proyecto
scraping_noticias/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ scraping/
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”œâ”€â”€ public/
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.ts

ğŸ” 5. Funcionalidades del Sistema
ğŸ‘¤ Modo Usuario

Registro e inicio de sesiÃ³n con JWT

Panel personal de noticias

Scraping manual

AnÃ¡lisis de noticias con IA

ExportaciÃ³n de datos a Excel

ChatBot integrado

ğŸ›¡ï¸ Modo Administrador

Ver lista de usuarios

Cambiar roles

Ver scraping ejecutado por usuarios

Gestionar noticias globales

Monitoreo de planes (Free / Plus)

ğŸ§  Funciones de IA

ClasificaciÃ³n automÃ¡tica de noticias

ResÃºmenes automÃ¡ticos

DetecciÃ³n de sentimiento

ChatBot con contexto

ğŸ“¡ 6. Endpoints Principales (Backend)
ğŸ‘¤ AutenticaciÃ³n
POST /auth/register
POST /auth/login

ğŸ” Scraping
POST /scraping/run       # Ejecuta scraping manual
GET  /scraping/history   # Historial del usuario

ğŸ§  Inteligencia Artificial
POST /ai/analyze          # Analiza noticia con IA
POST /ai/summarize        # Genera resumen
POST /ai/chat             # ChatBot

ğŸ“° Noticias
GET   /news/
GET   /news/{id}
DELETE /news/{id}

ğŸ›¡ï¸ Admin
GET /admin/users
PUT /admin/users/{id}/role

ğŸ§ª 7. Scripts de Scraping
Ejecutar scraping automÃ¡tico
python scraping/cron_scraper.py

Ejecutar scraping manual (modo desarrollo)
python scraping/scrape_rpp.py

ğŸ§¾ 8. ExportaciÃ³n a Excel

El usuario puede exportar toda su data:

Por categorÃ­a

Por fecha

Por portal

Por palabras clave

El backend envÃ­a archivo .xlsx.

ğŸ”’ 9. Sistema de Planes
Plan	LÃ­mite	Funciones
Free	20 noticias por dÃ­a	Scraping manual, exportaciÃ³n
Plus	Ilimitado	IA, scraping avanzado, chatbot
ğŸ’¼ 10. Idea de Negocio (Business Model)

Tu proyecto es un SaaS de monitoreo y anÃ¡lisis inteligente de noticias, enfocado en:

ğŸŸ¦ Tipo de negocio:

Plataforma de anÃ¡lisis informativo (News Intelligence Platform)

ğŸ¯ Cliente objetivo:

Periodistas

Empresas de marketing

PolitÃ³logos

Universidades

Agencias de noticias

Analistas digitales

ğŸ’° Fuentes de ingresos:

SuscripciÃ³n mensual (Free â†’ Plus)

Plan empresarial

API de datos

Servicios de anÃ¡lisis avanzado con IA

ğŸ“„ 11. Licencia

MIT License.

ğŸ™Œ 12. Autor

Milton Edward Humpiri Flores
UPeU â€“ 2025
